{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6318833,"sourceType":"datasetVersion","datasetId":3636171}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import needed libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport random\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\nfrom operator import add\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:24.126635Z","iopub.execute_input":"2023-08-17T20:23:24.127002Z","iopub.status.idle":"2023-08-17T20:23:28.094197Z","shell.execute_reply.started":"2023-08-17T20:23:24.126971Z","shell.execute_reply":"2023-08-17T20:23:28.0932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create helper classes and functions","metadata":{}},{"cell_type":"markdown","source":"### Dataset class","metadata":{}},{"cell_type":"code","source":"class DriveDataset(Dataset):\n    def __init__(self, images_path, masks_path):\n\n        self.images_path = images_path\n        self.masks_path = masks_path\n        self.n_samples = len(images_path)\n\n    def __getitem__(self, index):\n        \"\"\" Reading image \"\"\"\n        image = cv2.imread(self.images_path[index], cv2.IMREAD_COLOR)\n        image = image/255.0\n        image = np.transpose(image, (2, 0, 1))\n        image = image.astype(np.float32)\n        image = torch.from_numpy(image)\n\n        \"\"\" Reading mask \"\"\"\n        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)\n        mask = mask/255.0\n        mask = np.expand_dims(mask, axis=0)\n        mask = mask.astype(np.float32)\n        mask = torch.from_numpy(mask)\n\n        return image, mask\n\n    def __len__(self):\n        return self.n_samples","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:35.112667Z","iopub.execute_input":"2023-08-17T20:23:35.113221Z","iopub.status.idle":"2023-08-17T20:23:35.121952Z","shell.execute_reply.started":"2023-08-17T20:23:35.113189Z","shell.execute_reply":"2023-08-17T20:23:35.120962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Unet helper classes","metadata":{}},{"cell_type":"code","source":"# Build Conv_layer\nclass conv_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_c)\n\n        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_c)\n\n        self.relu = nn.ReLU()\n\n    def forward(self, inputs):\n        x = self.conv1(inputs)\n        x = self.bn1(x)\n        x = self.relu(x)\n\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:35.954887Z","iopub.execute_input":"2023-08-17T20:23:35.955258Z","iopub.status.idle":"2023-08-17T20:23:35.963198Z","shell.execute_reply.started":"2023-08-17T20:23:35.955227Z","shell.execute_reply":"2023-08-17T20:23:35.961944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Encoder section\nclass encoder_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n\n        self.conv = conv_block(in_c, out_c)\n        self.pool = nn.MaxPool2d((2, 2))\n\n    def forward(self, inputs):\n        x = self.conv(inputs)\n        p = self.pool(x)\n\n        return x, p","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:36.201228Z","iopub.execute_input":"2023-08-17T20:23:36.20206Z","iopub.status.idle":"2023-08-17T20:23:36.208401Z","shell.execute_reply.started":"2023-08-17T20:23:36.202024Z","shell.execute_reply":"2023-08-17T20:23:36.207253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Decoder section\nclass decoder_block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n\n        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n        self.conv = conv_block(out_c+out_c, out_c)\n\n    def forward(self, inputs, skip):\n        x = self.up(inputs)\n        x = torch.cat([x, skip], axis=1)\n        x = self.conv(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:36.440124Z","iopub.execute_input":"2023-08-17T20:23:36.440504Z","iopub.status.idle":"2023-08-17T20:23:36.447454Z","shell.execute_reply.started":"2023-08-17T20:23:36.440472Z","shell.execute_reply":"2023-08-17T20:23:36.446433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Unet architecture\nclass build_unet(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Encoder\n        self.e1 = encoder_block(3, 64)\n        self.e2 = encoder_block(64, 128)\n        self.e3 = encoder_block(128, 256)\n        self.e4 = encoder_block(256, 512)\n\n        # Bottleneck\n        self.b = conv_block(512, 1024)\n\n        # Decoder\n        self.d1 = decoder_block(1024, 512)\n        self.d2 = decoder_block(512, 256)\n        self.d3 = decoder_block(256, 128)\n        self.d4 = decoder_block(128, 64)\n\n        # Classifier\n        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n        \n    def forward(self, inputs):\n        # Encoder\n        s1, p1 = self.e1(inputs)\n        s2, p2 = self.e2(p1)\n        s3, p3 = self.e3(p2)\n        s4, p4 = self.e4(p3)\n\n        # Bottleneck\n        b = self.b(p4)\n\n        # Decoder\n        d1 = self.d1(b, s4)\n        d2 = self.d2(d1, s3)\n        d3 = self.d3(d2, s2)\n        d4 = self.d4(d3, s1)\n\n        outputs = self.outputs(d4)\n\n        return outputs","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:36.692829Z","iopub.execute_input":"2023-08-17T20:23:36.693489Z","iopub.status.idle":"2023-08-17T20:23:36.703831Z","shell.execute_reply.started":"2023-08-17T20:23:36.693456Z","shell.execute_reply":"2023-08-17T20:23:36.702526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Losses classes","metadata":{}},{"cell_type":"code","source":"# Dice Coefficient\nclass DiceLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n\n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = torch.sigmoid(inputs)\n\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n\n        return 1 - dice","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:37.166889Z","iopub.execute_input":"2023-08-17T20:23:37.167727Z","iopub.status.idle":"2023-08-17T20:23:37.177255Z","shell.execute_reply.started":"2023-08-17T20:23:37.167692Z","shell.execute_reply":"2023-08-17T20:23:37.176212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dice Binary Cross Entropy Coefficient\nclass DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n\n        #comment out if your model contains a sigmoid or equivalent activation layer\n        inputs = torch.sigmoid(inputs)\n\n        #flatten label and prediction tensors\n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n\n        intersection = (inputs * targets).sum()\n        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        Dice_BCE = BCE + dice_loss\n\n        return Dice_BCE","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:37.402926Z","iopub.execute_input":"2023-08-17T20:23:37.403623Z","iopub.status.idle":"2023-08-17T20:23:37.410977Z","shell.execute_reply.started":"2023-08-17T20:23:37.403584Z","shell.execute_reply":"2023-08-17T20:23:37.410008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to seed the randomness","metadata":{}},{"cell_type":"code","source":"def seeding(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:37.914956Z","iopub.execute_input":"2023-08-17T20:23:37.915646Z","iopub.status.idle":"2023-08-17T20:23:37.921757Z","shell.execute_reply.started":"2023-08-17T20:23:37.915595Z","shell.execute_reply":"2023-08-17T20:23:37.92084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to create a new directory","metadata":{}},{"cell_type":"code","source":"def create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:38.626756Z","iopub.execute_input":"2023-08-17T20:23:38.627118Z","iopub.status.idle":"2023-08-17T20:23:38.632921Z","shell.execute_reply.started":"2023-08-17T20:23:38.627089Z","shell.execute_reply":"2023-08-17T20:23:38.631891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to calculate the taken time","metadata":{}},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:39.240001Z","iopub.execute_input":"2023-08-17T20:23:39.24108Z","iopub.status.idle":"2023-08-17T20:23:39.251893Z","shell.execute_reply.started":"2023-08-17T20:23:39.241044Z","shell.execute_reply":"2023-08-17T20:23:39.25091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to train the model","metadata":{}},{"cell_type":"code","source":"def train(model, loader, optimizer, loss_fn, device):\n    epoch_loss = 0.0\n\n    model.train()\n    for x, y in loader:\n        x = x.to(device, dtype=torch.float32)\n        y = y.to(device, dtype=torch.float32)\n\n        optimizer.zero_grad()\n        y_pred = model(x)\n        loss = loss_fn(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n    epoch_loss = epoch_loss/len(loader)\n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:39.931283Z","iopub.execute_input":"2023-08-17T20:23:39.931675Z","iopub.status.idle":"2023-08-17T20:23:39.938241Z","shell.execute_reply.started":"2023-08-17T20:23:39.931644Z","shell.execute_reply":"2023-08-17T20:23:39.937314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to evaluate the model","metadata":{}},{"cell_type":"code","source":"def evaluate(model, loader, loss_fn, device):\n    epoch_loss = 0.0\n\n    model.eval()\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device, dtype=torch.float32)\n            y = y.to(device, dtype=torch.float32)\n\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n            epoch_loss += loss.item()\n\n        epoch_loss = epoch_loss / len(loader)\n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:40.649913Z","iopub.execute_input":"2023-08-17T20:23:40.650782Z","iopub.status.idle":"2023-08-17T20:23:40.657649Z","shell.execute_reply.started":"2023-08-17T20:23:40.650746Z","shell.execute_reply":"2023-08-17T20:23:40.656587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### Get data paths","metadata":{}},{"cell_type":"code","source":"# Seeding\nseeding(42)\n\n# Create files directory to store checkpoint file\ncreate_dir(\"files\")\n\n#  Get data paths\ntrain_x = sorted(glob(\"/kaggle/input/retina-blood-vessel/Data/train/image/*\"))\ntrain_y = sorted(glob(\"/kaggle/input/retina-blood-vessel/Data/train/mask/*\"))\n\nvalid_x = sorted(glob(\"/kaggle/input/retina-blood-vessel/Data/test/image/*\"))\nvalid_y = sorted(glob(\"/kaggle/input/retina-blood-vessel/Data/test/mask/*\"))\n\ndata_str = f\"Dataset Size:\\nTrain: {len(train_x)} - Valid: {len(valid_x)}\\n\"\nprint(data_str)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:41.985496Z","iopub.execute_input":"2023-08-17T20:23:41.986195Z","iopub.status.idle":"2023-08-17T20:23:42.047295Z","shell.execute_reply.started":"2023-08-17T20:23:41.986161Z","shell.execute_reply":"2023-08-17T20:23:42.046293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set hyperparameters","metadata":{}},{"cell_type":"code","source":"H = 512\nW = 512\nsize = (H, W)\nbatch_size = 2\nlr = 1e-4\ncheckpoint_path = \"files/checkpoint.pth\"","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:43.035747Z","iopub.execute_input":"2023-08-17T20:23:43.036307Z","iopub.status.idle":"2023-08-17T20:23:43.041429Z","shell.execute_reply.started":"2023-08-17T20:23:43.036271Z","shell.execute_reply":"2023-08-17T20:23:43.040402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load dataset","metadata":{}},{"cell_type":"code","source":"train_dataset = DriveDataset(train_x, train_y)\nvalid_dataset = DriveDataset(valid_x, valid_y)\n\ntrain_loader = DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=2\n)\n\nvalid_loader = DataLoader(\n    dataset=valid_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=2\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:23:44.610787Z","iopub.execute_input":"2023-08-17T20:23:44.61116Z","iopub.status.idle":"2023-08-17T20:23:44.617852Z","shell.execute_reply.started":"2023-08-17T20:23:44.611128Z","shell.execute_reply":"2023-08-17T20:23:44.616597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unet Model","metadata":{}},{"cell_type":"code","source":"# Set cuda device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Build model\nmodel = build_unet()\nmodel = model.to(device)\n\n# Set Optimizer and Loss\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\nloss_fn = DiceBCELoss()","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:30:08.845484Z","iopub.execute_input":"2023-08-17T20:30:08.846084Z","iopub.status.idle":"2023-08-17T20:30:12.362507Z","shell.execute_reply.started":"2023-08-17T20:30:08.846049Z","shell.execute_reply":"2023-08-17T20:30:12.361508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"best_valid_loss = float(\"inf\")\nnum_epochs = 50\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n\n    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n\n    # Saving the model\n    if valid_loss < best_valid_loss:\n        print(f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}. Saving checkpoint: {checkpoint_path}\")\n\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), checkpoint_path)\n\n    end_time = time.time()\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    data_str = f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n'\n    data_str += f'\\tTrain Loss: {train_loss:.3f}\\n'\n    data_str += f'\\tVal. Loss: {valid_loss:.3f}\\n'\n    print(data_str)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:35:19.32993Z","iopub.execute_input":"2023-08-17T20:35:19.330604Z","iopub.status.idle":"2023-08-17T20:45:56.800005Z","shell.execute_reply.started":"2023-08-17T20:35:19.330562Z","shell.execute_reply":"2023-08-17T20:45:56.79792Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"markdown","source":"### Function to get metrics for evaluation","metadata":{}},{"cell_type":"code","source":"def calculate_metrics(y_true, y_pred):\n    # Ground truth\n    y_true = y_true.cpu().numpy()\n    y_true = y_true > 0.5\n    y_true = y_true.astype(np.uint8)\n    y_true = y_true.reshape(-1)\n\n    # Prediction\n    y_pred = y_pred.cpu().numpy()\n    y_pred = y_pred > 0.5\n    y_pred = y_pred.astype(np.uint8)\n    y_pred = y_pred.reshape(-1)\n\n    score_jaccard = jaccard_score(y_true, y_pred)\n    score_f1 = f1_score(y_true, y_pred)\n    score_recall = recall_score(y_true, y_pred)\n    score_precision = precision_score(y_true, y_pred)\n    score_acc = accuracy_score(y_true, y_pred)\n\n    return [score_jaccard, score_f1, score_recall, score_precision, score_acc]","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:46:51.830348Z","iopub.execute_input":"2023-08-17T20:46:51.830795Z","iopub.status.idle":"2023-08-17T20:46:51.841658Z","shell.execute_reply.started":"2023-08-17T20:46:51.830755Z","shell.execute_reply":"2023-08-17T20:46:51.840621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Function to parse the mask","metadata":{}},{"cell_type":"code","source":"def mask_parse(mask):\n    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n    return mask","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:48:47.783538Z","iopub.execute_input":"2023-08-17T20:48:47.784513Z","iopub.status.idle":"2023-08-17T20:48:47.790136Z","shell.execute_reply.started":"2023-08-17T20:48:47.784477Z","shell.execute_reply":"2023-08-17T20:48:47.789154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get test data","metadata":{}},{"cell_type":"code","source":"#  Seeding\nseeding(42)\n\n# Folders\ncreate_dir(\"results\")\n\n# Load dataset\ntest_x = sorted(glob(\"/kaggle/input/retina-blood-vessel/Data/test/image/*\"))\ntest_y = sorted(glob(\"/kaggle/input/retina-blood-vessel/Data/test/mask/*\"))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:54:10.948485Z","iopub.execute_input":"2023-08-17T20:54:10.949191Z","iopub.status.idle":"2023-08-17T20:54:10.967978Z","shell.execute_reply.started":"2023-08-17T20:54:10.949158Z","shell.execute_reply":"2023-08-17T20:54:10.96697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load checkpoints file","metadata":{}},{"cell_type":"code","source":"checkpoint_path = \"files/checkpoint.pth\"\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = build_unet()\nmodel = model.to(device)\nmodel.load_state_dict(torch.load(checkpoint_path, map_location=device))\nmodel.eval()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-08-17T20:54:30.334492Z","iopub.execute_input":"2023-08-17T20:54:30.334902Z","iopub.status.idle":"2023-08-17T20:54:30.701885Z","shell.execute_reply.started":"2023-08-17T20:54:30.334873Z","shell.execute_reply":"2023-08-17T20:54:30.700733Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\ntime_taken = []\n\nfor i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n    # Extract the name\n    name = x.split(\"/\")[-1].split(\".\")[0]\n\n    # Reading image\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## (512, 512, 3)\n    x = np.transpose(image, (2, 0, 1))      ## (3, 512, 512)\n    x = x/255.0\n    x = np.expand_dims(x, axis=0)           ## (1, 3, 512, 512)\n    x = x.astype(np.float32)\n    x = torch.from_numpy(x)\n    x = x.to(device)\n\n    # Reading mask\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n    y = np.expand_dims(mask, axis=0)            ## (1, 512, 512)\n    y = y / 255.0\n    y = np.expand_dims(y, axis=0)               ## (1, 1, 512, 512)\n    y = y.astype(np.float32)\n    y = torch.from_numpy(y)\n    y = y.to(device)\n\n    with torch.no_grad():\n        # Prediction and Calculating FPS\n        start_time = time.time()\n        pred_y = model(x)\n        pred_y = torch.sigmoid(pred_y)\n        total_time = time.time() - start_time\n        time_taken.append(total_time)\n\n\n        score = calculate_metrics(y, pred_y)\n        metrics_score = list(map(add, metrics_score, score))\n        pred_y = pred_y[0].cpu().numpy()        ## (1, 512, 512)\n        pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n        pred_y = pred_y > 0.5\n        pred_y = np.array(pred_y, dtype=np.uint8)\n\n    # Saving masks\n    ori_mask = mask_parse(mask)\n    pred_y = mask_parse(pred_y)\n    line = np.ones((size[1], 10, 3)) * 128\n\n    cat_images = np.concatenate(\n        [image, line, ori_mask, line, pred_y * 255], axis=1\n    )\n    cv2.imwrite(f\"results/{name}.png\", cat_images)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:54:34.886025Z","iopub.execute_input":"2023-08-17T20:54:34.886806Z","iopub.status.idle":"2023-08-17T20:54:42.008882Z","shell.execute_reply.started":"2023-08-17T20:54:34.886769Z","shell.execute_reply":"2023-08-17T20:54:42.007899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Evaluation","metadata":{}},{"cell_type":"code","source":"jaccard = metrics_score[0] / len(test_x)\nf1 = metrics_score[1] / len(test_x)\nrecall = metrics_score[2] / len(test_x)\nprecision = metrics_score[3] / len(test_x)\nacc = metrics_score[4] / len(test_x)\nprint(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f}\")\n\nfps = 1 / np.mean(time_taken)\nprint(\"FPS: \", fps)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:55:21.106677Z","iopub.execute_input":"2023-08-17T20:55:21.107046Z","iopub.status.idle":"2023-08-17T20:55:21.114473Z","shell.execute_reply.started":"2023-08-17T20:55:21.107015Z","shell.execute_reply":"2023-08-17T20:55:21.113101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show result","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimg = plt.imread('/kaggle/working/results/11.png')\nplt.figure(figsize=(15, 8))\nplt.imshow(img)\nplt.axis('off')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:59:43.279522Z","iopub.execute_input":"2023-08-17T20:59:43.279932Z","iopub.status.idle":"2023-08-17T20:59:43.72778Z","shell.execute_reply.started":"2023-08-17T20:59:43.279901Z","shell.execute_reply":"2023-08-17T20:59:43.726875Z"},"trusted":true},"execution_count":null,"outputs":[]}]}